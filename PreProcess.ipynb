{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Process Taxi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to pre-process taxi data\n",
    "def preprocess_data(filename, arr,PATH):\n",
    "    final_data = []\n",
    "    \n",
    "    for doc in arr:\n",
    "        \n",
    "        taxi = pd.read_csv(PATH + filename + doc)\n",
    "        # remove impossible data such as tip less than $0. All exaplined in report\n",
    "        taxi_impossible_vals_removed = taxi[(taxi['tip_amount']>=0) &\\\n",
    "             (taxi['trip_distance']>0) & (taxi['trip_distance']<25) &\\\n",
    "             (taxi['fare_amount']>=2.5) & (taxi['passenger_count']>0) &\\\n",
    "             (taxi['payment_type']==1)& (taxi['extra']>=0)].copy()\n",
    "\n",
    "        # keep only the features that matter - also explained in report\n",
    "        taxi_clean = taxi_impossible_vals_removed[['tpep_pickup_datetime','trip_distance','PULocationID',\\\n",
    "                           'DOLocationID','fare_amount','tip_amount','total_amount','extra','mta_tax',\\\n",
    "                           'tolls_amount','improvement_surcharge']]\n",
    "        # column names of taxi data\n",
    "        columns = list(taxi_clean.columns)\n",
    "        \n",
    "        # summary statistics of taxi data\n",
    "        info = taxi_clean.describe().transpose()\n",
    "        \n",
    "        # remove outliers\n",
    "        for index, col in info.iterrows():\n",
    "            \n",
    "            if index in ['VendorID', 'tpep_pickup_datetime','tpep_dropoff_datetime', 'PULocationID','DOLocationID']:\n",
    "                continue\n",
    "            # outliers defined as outsisde of x1.5 the Inter Quartile Range (IQR)\n",
    "            IQR = col[\"75%\"] - col[\"25%\"]\n",
    "\n",
    "            upper_lim = col[\"75%\"] + (IQR * 1.5)\n",
    "            lower_lim = col[\"25%\"] - (IQR * 1.5)\n",
    "            \n",
    "            taxi_clean=taxi_clean.loc[taxi_clean[index]<= upper_lim]\n",
    "            taxi_clean=taxi_clean.loc[taxi_clean[index]>= lower_lim]\n",
    "        \n",
    "        \n",
    "        final_data.append(taxi_clean)\n",
    "    \n",
    "    final_taxi = pd.concat(final_data) \n",
    "    # return a cleaned dataframe\n",
    "    return final_taxi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function used to extract features of pickup date, pickup hour and pickup month from\n",
    "# datetime objects. \n",
    "def get_datetime(data):\n",
    "    \n",
    "    data_dates = data.copy()\n",
    "    # use the pickup datetime data\n",
    "    data_dates['tpep_pickup_datetime'] = pd.to_datetime(data.tpep_pickup_datetime)\n",
    "    # extract date\n",
    "    data_dates['pickup_date'] = data_dates['tpep_pickup_datetime'].dt.date # Extract date\n",
    "    # extract hour\n",
    "    data_dates['pickup_hour'] = data_dates['tpep_pickup_datetime'].dt.hour\n",
    "    # extract month\n",
    "    data_dates['pickup_month']=data_dates['tpep_pickup_datetime'].dt.month\n",
    "    # sort by date of pick up\n",
    "    data_dates.sort_values(by = ['pickup_date'],inplace=True)\n",
    "    # remove datetime object\n",
    "    data_dates.drop(['tpep_pickup_datetime'], axis = 1, inplace = True)\n",
    "    # return dataframe\n",
    "    return data_dates.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to web scrape weather data. \n",
    "\n",
    "# webpages saved as files here.\n",
    "WEATHER_PATH = '/Users/Work/Documents/2020/Sem 2/Applied_Data_Science/Assignment2/Weather/'\n",
    "\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_month_weather(year_month):\n",
    "    \n",
    "    with open(WEATHER_PATH+year_month+\".html\") as file:\n",
    "        soup = BeautifulSoup(file.read(), \"html.parser\")\n",
    "    tables = soup.find_all(\"table\", \"days ng-star-inserted\")\n",
    "    \n",
    "    # Get data\n",
    "    table_data = [\n",
    "        [col.get_text() for col in row.find_all('td') if len(col.get_text())>10] \n",
    "        for row in tables[0].find_all(\"tr\")\n",
    "    ]\n",
    "    table_data = [data for data in table_data if len(data)>0]\n",
    "    table_data[1] = [col.split(\"  \") for col in table_data[1]]\n",
    "    \n",
    "    table_data.append([np.asarray(col).reshape((-1, 3)) for col in table_data[1][1:-1]])\n",
    "    \n",
    "    temp_table = [np.asarray(table_data[1][0])]\n",
    "    \n",
    "    for col in table_data[2]:\n",
    "        temp_table.append(col)\n",
    "        \n",
    "    temp_table.append(np.asarray(table_data[1][-1]))\n",
    "    \n",
    "    final_table = [\n",
    "        [temp_table[col][row] for col in range(len(temp_table))] \n",
    "        for row in range(len(temp_table[1]))\n",
    "    ]\n",
    "    \n",
    "    final_table = [\n",
    "        [final_table[row][0]] +\n",
    "        [item for sublist in final_table[row][1:-1] for item in sublist] +\n",
    "        [final_table[row][-1]]\n",
    "        for row in range(len(final_table))\n",
    "    ]\n",
    "    \n",
    "    final_table.insert(0, ['Day'] +\n",
    "                       [col_name for duplicate_cols in [\n",
    "                           [item, item, item] for item in table_data[0][:-1]\n",
    "                       ] for col_name in duplicate_cols] +\n",
    "                       [table_data[0][-1]])\n",
    "    \n",
    "    return final_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_per_year(year):\n",
    "    \n",
    "    df_lst = []\n",
    "    for i in range(1,13):\n",
    "        # access each months weather data. \n",
    "        month = str(year + i)\n",
    "        \n",
    "        # call get month weather data to convert to a table\n",
    "        tmp = get_month_weather(month)\n",
    "        \n",
    "        if i == 1:\n",
    "            row = 1       \n",
    "        else:\n",
    "            row = 2\n",
    "        # convert to dataframe   \n",
    "        df = pd.DataFrame(tmp[row:-1], columns=tmp[0])\n",
    "            \n",
    "        # create month column\n",
    "        df[\"Month\"] = i\n",
    "        # append to list of dataframes for each month\n",
    "        df_lst.append(df)\n",
    "        \n",
    "    # concatenate all the months to form a dataframe of the years worth of weather data\n",
    "    weather = pd.concat(df_lst).reset_index()\n",
    "    \n",
    "    # return weather data for the year\n",
    "    return weather\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_date_time(year,weather_data):\n",
    "    \n",
    "    # create new column called date in weather data\n",
    "    weather_data['Date'] = \"\"\n",
    "    \n",
    "    for index,col in weather_data.iterrows():\n",
    "    \n",
    "        if index == 0:\n",
    "            continue\n",
    "        \n",
    "        # extract date and date \n",
    "        weather_data.loc[index, 'Date'] = datetime.date(year,col['Month'],int(col['Day']))\n",
    "    # keep only tempreature, windspeed and precipitation \n",
    "    weather_data = weather_data[['Temperature (Â° F)','Wind Speed (mph)','Precipitation (in)','Date']]\n",
    "    \n",
    "    # return weather data\n",
    "    return weather_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Pre-Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_preprocess(PATH,filename):\n",
    "    \n",
    "    data = pd.read_csv(PATH + filename)\n",
    "    \n",
    "    # remove extra columns \n",
    "    data.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "    data.drop(['index'], axis = 1, inplace = True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create response variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target(data):\n",
    "    # group by location of pickup, the date and then the hour\n",
    "    data_by_hour = data.groupby(['PULocationID','pickup_date','pickup_hour']).mean().reset_index()\n",
    "    # find how many trips occured in each pick up zone, for each hour on each day \n",
    "    trips_per_hour = data.groupby(['PULocationID','pickup_date','pickup_hour']).size().reset_index()\n",
    "    # trips per hour is the response variable \n",
    "    data_by_hour['Trips_per_hour'] = trips_per_hour[0]\n",
    "    \n",
    "    return data_by_hour"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
